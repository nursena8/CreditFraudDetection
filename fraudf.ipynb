{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":23498,"sourceType":"datasetVersion","datasetId":310}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold, StratifiedKFold\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-16T12:05:09.054687Z","iopub.execute_input":"2024-05-16T12:05:09.055318Z","iopub.status.idle":"2024-05-16T12:05:09.701363Z","shell.execute_reply.started":"2024-05-16T12:05:09.055286Z","shell.execute_reply":"2024-05-16T12:05:09.700489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# credit card Fraud Detection\n# Veri seti:\n* Bu proje : kredi kartının kullaıldığı her yerde bulunan kredi kartı dolandırıcılık tespiti yapılmasını amaçlamaktadır.BAnkalarda,e-commerce(e ticaret siteleri),ve kredi kartının geçtiği her yerde karşımıza çıkabilir.\n* amaç :kredi kartı dolandırıclık tespiti yaparak tahminde bulunmak ve tespit etmektir.\n* sınıflandırma projesidir.machine learning kullanılacaktır.\n* v1 -v29 feature değişkenleri standardlaştırlımış.\n* işem yapılan yer, lokasyon,site gibi değerler bunlar gizlenmiştir.\n* bizden beklenen bu v columnlarından önemli olanları bulup frauda sebep verenleri bulmaktır.","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/creditcardfraud/creditcard.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:05:09.703323Z","iopub.execute_input":"2024-05-16T12:05:09.704100Z","iopub.status.idle":"2024-05-16T12:05:13.071355Z","shell.execute_reply.started":"2024-05-16T12:05:09.704066Z","shell.execute_reply":"2024-05-16T12:05:13.070289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df #id column primary keydir v1-v29 columlartı gizlenmiş feature dır.yani bunlar müşteriye ait herhangi bir özelliktir.","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:05:13.072628Z","iopub.execute_input":"2024-05-16T12:05:13.073044Z","iopub.status.idle":"2024-05-16T12:05:13.161735Z","shell.execute_reply.started":"2024-05-16T12:05:13.072992Z","shell.execute_reply":"2024-05-16T12:05:13.160803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# amount=ücret miktarıdır. class 1 ise sahtekarlık vardır. 0 ise yoktur demektir.","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:05:13.164320Z","iopub.execute_input":"2024-05-16T12:05:13.165179Z","iopub.status.idle":"2024-05-16T12:05:13.168653Z","shell.execute_reply.started":"2024-05-16T12:05:13.165143Z","shell.execute_reply":"2024-05-16T12:05:13.167804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.Class.value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:05:13.169640Z","iopub.execute_input":"2024-05-16T12:05:13.169874Z","iopub.status.idle":"2024-05-16T12:05:13.190214Z","shell.execute_reply.started":"2024-05-16T12:05:13.169853Z","shell.execute_reply":"2024-05-16T12:05:13.189238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"%{df.Class.value_counts()[0]/len(df) *100} fraud olmayan\")\nprint(f\"%{df.Class.value_counts()[1]/len(df)*100} fraud\")","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:05:13.191488Z","iopub.execute_input":"2024-05-16T12:05:13.192343Z","iopub.status.idle":"2024-05-16T12:05:13.203179Z","shell.execute_reply.started":"2024-05-16T12:05:13.192309Z","shell.execute_reply":"2024-05-16T12:05:13.202196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum().max()","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:05:13.204282Z","iopub.execute_input":"2024-05-16T12:05:13.204537Z","iopub.status.idle":"2024-05-16T12:05:13.227857Z","shell.execute_reply.started":"2024-05-16T12:05:13.204515Z","shell.execute_reply":"2024-05-16T12:05:13.227044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:05:13.228805Z","iopub.execute_input":"2024-05-16T12:05:13.229079Z","iopub.status.idle":"2024-05-16T12:05:13.235039Z","shell.execute_reply.started":"2024-05-16T12:05:13.229056Z","shell.execute_reply":"2024-05-16T12:05:13.234128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(df,x=\"Class\") #hemen hemen 1/0 eşit gibi görünüyor.","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:05:13.237088Z","iopub.execute_input":"2024-05-16T12:05:13.237429Z","iopub.status.idle":"2024-05-16T12:05:13.483086Z","shell.execute_reply.started":"2024-05-16T12:05:13.237405Z","shell.execute_reply":"2024-05-16T12:05:13.482200Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:04:47.144753Z","iopub.status.idle":"2024-05-16T12:04:47.145108Z","shell.execute_reply.started":"2024-05-16T12:04:47.144913Z","shell.execute_reply":"2024-05-16T12:04:47.144926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#we see that we have sclaed feature but we have to scale all feature (Time ,Amount) to create model.We have used Robust\n#scaler because this choice more resilince for outlier values\n\nfrom sklearn.preprocessing import RobustScaler\n\nscaler = RobustScaler()\ndf.Time = scaler.fit_transform(df.Time.values.reshape(-1,1))\ndf.Amount = scaler.fit_transform(df.Amount.values.reshape(-1,1))","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:05:16.871673Z","iopub.execute_input":"2024-05-16T12:05:16.872035Z","iopub.status.idle":"2024-05-16T12:05:16.895881Z","shell.execute_reply.started":"2024-05-16T12:05:16.871994Z","shell.execute_reply":"2024-05-16T12:05:16.895142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:05:17.653854Z","iopub.execute_input":"2024-05-16T12:05:17.654699Z","iopub.status.idle":"2024-05-16T12:05:17.785212Z","shell.execute_reply.started":"2024-05-16T12:05:17.654668Z","shell.execute_reply":"2024-05-16T12:05:17.784221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# undersample","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = df.drop('Class', axis=1)\ny = df['Class']\n\nXtrain, Xtest, ytrain,  ytest = train_test_split(X, y, test_size=0.2, random_state=818)\n\ndf = df.sample(frac=1)\nfraud = df.loc[df.Class == 1]\nnon_fraud = df.loc[df.Class == 0][:492]\n\ndistributed_df = pd.concat([fraud, non_fraud])\n\nnew_df = distributed_df.sample(frac=1, random_state=818)\n\nnew_df.head()\n\nsns.countplot(new_df,x=\"Class\")","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:05:18.976801Z","iopub.execute_input":"2024-05-16T12:05:18.977530Z","iopub.status.idle":"2024-05-16T12:05:19.397140Z","shell.execute_reply.started":"2024-05-16T12:05:18.977493Z","shell.execute_reply":"2024-05-16T12:05:19.396282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"relationship = new_df.corr()\nsns.heatmap(relationship)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:05:19.452809Z","iopub.execute_input":"2024-05-16T12:05:19.453152Z","iopub.status.idle":"2024-05-16T12:05:19.928886Z","shell.execute_reply.started":"2024-05-16T12:05:19.453125Z","shell.execute_reply":"2024-05-16T12:05:19.928052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* 16-17-18 features have high relationship eventually that can be more re","metadata":{}},{"cell_type":"code","source":"from scipy.stats import norm\nnew_df['V14'].loc[new_df['Class'] == 1].values\nnew_df['V12'].loc[new_df['Class'] == 1].values\nnew_df['V17'].loc[new_df['Class'] == 1].values\nnew_df['V18'].loc[new_df['Class'] == 1].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1,3 ,figsize=(20,4))\naxes[0].set_title(\"v11 class comparisons\")\naxes[1].set_title(\"v2 class comparisons \")\naxes[2].set_title(\"v4 class comparisons\")\nsns.boxplot(x=\"Class\", y=\"V11\", data=new_df,   ax=axes[0])\nsns.boxplot(x=\"Class\", y=\"V2\", data=new_df,   ax=axes[1])\nsns.boxplot(x=\"Class\", y=\"V4\", data=new_df,   ax=axes[2])","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:05:20.761123Z","iopub.execute_input":"2024-05-16T12:05:20.761921Z","iopub.status.idle":"2024-05-16T12:05:21.356154Z","shell.execute_reply.started":"2024-05-16T12:05:20.761892Z","shell.execute_reply":"2024-05-16T12:05:21.355351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Outlier for undersample technique","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,6))\nsns.boxplot(data = new_df)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:05:21.357682Z","iopub.execute_input":"2024-05-16T12:05:21.357989Z","iopub.status.idle":"2024-05-16T12:05:22.143670Z","shell.execute_reply.started":"2024-05-16T12:05:21.357954Z","shell.execute_reply":"2024-05-16T12:05:22.142643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def outlier_zscore(data,threshold = 3):\n    global outliers,zscore\n    outliers = []\n    zscore = []\n    \n    mean = np.mean(data)\n    std = np.std(data)\n    for i in data:\n        z_score= (i - mean)/std \n        zscore.append(z_score)\n        if np.abs(z_score) > threshold:\n            outliers.append(i)\n    cleaned_data = [x for x in data if x not in outliers]\n    \n    print(\"Total number of outliers are\", len(outliers))\n    \n    return cleaned_data","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:05:23.061989Z","iopub.execute_input":"2024-05-16T12:05:23.062377Z","iopub.status.idle":"2024-05-16T12:05:23.069683Z","shell.execute_reply.started":"2024-05-16T12:05:23.062348Z","shell.execute_reply":"2024-05-16T12:05:23.068414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in df.columns:\n    print (i)\n    outlier_zscore(new_df[i])","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:05:23.809167Z","iopub.execute_input":"2024-05-16T12:05:23.809848Z","iopub.status.idle":"2024-05-16T12:05:23.899955Z","shell.execute_reply.started":"2024-05-16T12:05:23.809819Z","shell.execute_reply":"2024-05-16T12:05:23.899048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_list = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\n\ndef z_score_method(df,n,features):\n    \"\"\"\n    Takes a dataframe df of features and returns an index list corresponding to the observations \n    containing more than n outliers according to the z-score method.\n    \"\"\"\n    outlier_list = []\n    \n    for column in features:\n        data_mean = df[column].mean()\n        data_std = df[column].std()\n        threshold = 3\n        \n        z_score = abs( (df[column] - data_mean)/data_std )\n     \n        outlier_list_column =  df[z_score > threshold].index\n        \n        outlier_list.extend(outlier_list_column)\n        \n    outlier_list = Counter(outlier_list)        \n    multiple_outliers = list( k for k, v in outlier_list.items() if v > n )\n    \n    df1 = df[z_score > threshold]\n    print('Total number of outliers is:', df1.shape[0])\n    \n    return multiple_outliers\n# detecting outliers\n#Outliers_z_score = z_score_method(new_df,1,feature_list)\n\n# dropping outliers\n#new_df = new_df.drop(Outliers_z_score, axis = 0).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:05:24.469051Z","iopub.execute_input":"2024-05-16T12:05:24.469396Z","iopub.status.idle":"2024-05-16T12:05:24.479474Z","shell.execute_reply.started":"2024-05-16T12:05:24.469369Z","shell.execute_reply":"2024-05-16T12:05:24.478432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"execution":{"iopub.status.busy":"2024-05-16T10:38:45.243475Z","iopub.execute_input":"2024-05-16T10:38:45.244197Z","iopub.status.idle":"2024-05-16T10:38:45.254244Z","shell.execute_reply.started":"2024-05-16T10:38:45.244166Z","shell.execute_reply":"2024-05-16T10:38:45.253233Z"}}},{"cell_type":"code","source":"def outlier_thresholds(dataframe, col_names, q1=0.25, q3=0.75):\n    limits = {}\n    for col_name in col_names:\n        quartile1 = dataframe[col_name].quantile(q1)\n        quartile3 = dataframe[col_name].quantile(q3)\n        interquantile_range = quartile3 - quartile1\n        up_limit = quartile3 + 1.5 * interquantile_range\n        low_limit = quartile1 - 1.5 * interquantile_range\n        limits[col_name] = (low_limit, up_limit)\n    return limits\n\ndef replace_with_thresholds(dataframe, variable, low_limit, up_limit):\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n\ndef replace_outliers(dataframe, col_names, q1=0.25, q3=0.75):\n    limits = outlier_thresholds(dataframe, col_names, q1, q3)\n    for col_name in col_names:\n        low_limit, up_limit = limits[col_name]\n        dataframe_copy = dataframe.copy()  # Orjinal veriyi değiştirmemek için bir kopya alıyoruz.\n        outliers = dataframe_copy[(dataframe_copy[col_name] > up_limit) | (dataframe_copy[col_name] < low_limit)]\n        if not outliers.empty:\n            replace_with_thresholds(dataframe, col_name, low_limit, up_limit)\n    return dataframe\n\ndef check_outlier(dataframe, col_names, q1=0.25, q3=0.75):\n    outlier_dict = {}\n    for col_name in col_names:\n        low_limit, up_limit = outlier_thresholds(dataframe, [col_name], q1, q3)[col_name]\n        if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n            outlier_dict[col_name] = True\n        else:\n            outlier_dict[col_name] = False\n    return outlier_dict","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:05:26.255498Z","iopub.execute_input":"2024-05-16T12:05:26.256353Z","iopub.status.idle":"2024-05-16T12:05:26.267368Z","shell.execute_reply.started":"2024-05-16T12:05:26.256324Z","shell.execute_reply":"2024-05-16T12:05:26.266311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check_outlier(new_df,feature_list)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:05:26.985451Z","iopub.execute_input":"2024-05-16T12:05:26.985809Z","iopub.status.idle":"2024-05-16T12:05:27.057816Z","shell.execute_reply.started":"2024-05-16T12:05:26.985767Z","shell.execute_reply":"2024-05-16T12:05:27.056875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df = replace_outliers(new_df,feature_list)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:05:29.150947Z","iopub.execute_input":"2024-05-16T12:05:29.151318Z","iopub.status.idle":"2024-05-16T12:05:29.240779Z","shell.execute_reply.started":"2024-05-16T12:05:29.151291Z","shell.execute_reply":"2024-05-16T12:05:29.240052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check_outlier(new_df,feature_list)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:05:29.912119Z","iopub.execute_input":"2024-05-16T12:05:29.912896Z","iopub.status.idle":"2024-05-16T12:05:29.982594Z","shell.execute_reply.started":"2024-05-16T12:05:29.912868Z","shell.execute_reply":"2024-05-16T12:05:29.981647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1,3 ,figsize=(20,4))\naxes[0].set_title(\"v11 class comparisons\")\naxes[1].set_title(\"v2 class comparisons \")\naxes[2].set_title(\"v4 class comparisons\")\nsns.boxplot(x=\"Class\", y=\"V11\", data=new_df,   ax=axes[0])\nsns.boxplot(x=\"Class\", y=\"V2\", data=new_df,   ax=axes[1])\nsns.boxplot(x=\"Class\", y=\"V4\", data=new_df,   ax=axes[2])","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:05:30.599231Z","iopub.execute_input":"2024-05-16T12:05:30.599551Z","iopub.status.idle":"2024-05-16T12:05:31.191348Z","shell.execute_reply.started":"2024-05-16T12:05:30.599528Z","shell.execute_reply":"2024-05-16T12:05:31.190432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = new_df.drop(\"Class\",axis=1)\ny = new_df[\"Class\"]","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:05:31.336540Z","iopub.execute_input":"2024-05-16T12:05:31.336876Z","iopub.status.idle":"2024-05-16T12:05:31.343487Z","shell.execute_reply.started":"2024-05-16T12:05:31.336850Z","shell.execute_reply":"2024-05-16T12:05:31.342196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state=818)\n# Turn the values into an array for classification algorithms.\nx_train = x_train.values\nx_test = x_test.values\ny_train = y_train.values\ny_test = y_test.values","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:05:31.889301Z","iopub.execute_input":"2024-05-16T12:05:31.889680Z","iopub.status.idle":"2024-05-16T12:05:31.898335Z","shell.execute_reply.started":"2024-05-16T12:05:31.889650Z","shell.execute_reply":"2024-05-16T12:05:31.897390Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nclassifiers = {\n    \"LogisiticRegression\": LogisticRegression(),\n    \"KNN\": KNeighborsClassifier(),\n    \"Support Vector Classifier\": SVC(),\n    \"DecisionTreeClassifier\": DecisionTreeClassifier()\n}","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:05:32.696423Z","iopub.execute_input":"2024-05-16T12:05:32.697253Z","iopub.status.idle":"2024-05-16T12:05:32.877765Z","shell.execute_reply.started":"2024-05-16T12:05:32.697222Z","shell.execute_reply":"2024-05-16T12:05:32.876991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from imblearn.pipeline import make_pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import NearMiss\nfrom imblearn.metrics import classification_report_imbalanced\nfrom sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\nfrom sklearn.model_selection import KFold, StratifiedKFold,cross_val_score,GridSearchCV,cross_val_predict","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:05:33.423107Z","iopub.execute_input":"2024-05-16T12:05:33.423822Z","iopub.status.idle":"2024-05-16T12:05:33.533569Z","shell.execute_reply.started":"2024-05-16T12:05:33.423792Z","shell.execute_reply":"2024-05-16T12:05:33.532528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for key, classifier in classifiers.items():\n    classifier.fit(x_train, y_train)\n    training_score = cross_val_score(classifier, x_train, y_train, cv=5)\n    print(\"Classifiers: \", classifier.__class__.__name__, \"Has a training score of\", round(training_score.mean(), 2) * 100, \"% accuracy score\")","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:05:34.144591Z","iopub.execute_input":"2024-05-16T12:05:34.145513Z","iopub.status.idle":"2024-05-16T12:05:34.612541Z","shell.execute_reply.started":"2024-05-16T12:05:34.145463Z","shell.execute_reply":"2024-05-16T12:05:34.611660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_reg_params = {\"penalty\": ['l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n\ngrid_log_reg = GridSearchCV(LogisticRegression(max_iter=1000), log_reg_params)\ngrid_log_reg.fit(x_train, y_train)\nlog_reg = grid_log_reg.best_estimator_\n\nknears_params = {\"n_neighbors\": list(range(2,5,1)), 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}\n\ngrid_knears = GridSearchCV(KNeighborsClassifier(), knears_params)\ngrid_knears.fit(x_train, y_train)\n# KNears best estimator\nknears_neighbors = grid_knears.best_estimator_\n\n# Support Vector Classifier\nsvc_params = {'C': [0.5, 0.7, 0.9, 1], 'kernel': ['rbf', 'poly', 'sigmoid', 'linear']}\ngrid_svc = GridSearchCV(SVC(), svc_params)\ngrid_svc.fit(x_train, y_train)\n\n# SVC best estimator\nsvc = grid_svc.best_estimator_\n\n# DecisionTree Classifier\ntree_params = {\"criterion\": [\"gini\", \"entropy\"], \"max_depth\": list(range(2,4,1)), \n              \"min_samples_leaf\": list(range(5,7,1))}\ngrid_tree = GridSearchCV(DecisionTreeClassifier(), tree_params)\ngrid_tree.fit(x_train, y_train)\n\n# tree best estimator\ntree_clf = grid_tree.best_estimator_","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:05:34.848745Z","iopub.execute_input":"2024-05-16T12:05:34.849190Z","iopub.status.idle":"2024-05-16T12:05:38.571797Z","shell.execute_reply.started":"2024-05-16T12:05:34.849150Z","shell.execute_reply":"2024-05-16T12:05:38.570831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_reg_score = cross_val_score(log_reg, x_train, y_train, cv=5)\nprint('Logistic Regression Cross Validation Score: ', round(log_reg_score.mean() * 100, 2).astype(str) + '%')\n\n\nknears_score = cross_val_score(knears_neighbors, x_train, y_train, cv=5)\nprint('Knears Neighbors Cross Validation Score', round(knears_score.mean() * 100, 2).astype(str) + '%')\n\nsvc_score = cross_val_score(svc, x_train, y_train, cv=5)\nprint('Support Vector Classifier Cross Validation Score', round(svc_score.mean() * 100, 2).astype(str) + '%')\n\ntree_score = cross_val_score(tree_clf, x_train, y_train, cv=5)\nprint('DecisionTree Classifier Cross Validation Score', round(tree_score.mean() * 100, 2).astype(str) + '%')","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:05:38.573565Z","iopub.execute_input":"2024-05-16T12:05:38.574377Z","iopub.status.idle":"2024-05-16T12:05:38.970426Z","shell.execute_reply.started":"2024-05-16T12:05:38.574345Z","shell.execute_reply":"2024-05-16T12:05:38.969494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_reg_pred = cross_val_predict(log_reg, x_train, y_train, cv=5,\n                             method=\"decision_function\")\n\nknears_pred = cross_val_predict(knears_neighbors, x_train, y_train, cv=5)\n\nsvc_pred = cross_val_predict(svc, x_train, y_train, cv=5,\n                             method=\"decision_function\")\n\ntree_pred = cross_val_predict(tree_clf, x_train, y_train, cv=5)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:05:38.971676Z","iopub.execute_input":"2024-05-16T12:05:38.972097Z","iopub.status.idle":"2024-05-16T12:05:39.334362Z","shell.execute_reply.started":"2024-05-16T12:05:38.972060Z","shell.execute_reply":"2024-05-16T12:05:39.333369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Logistic Regression: ', roc_auc_score(y_train, log_reg_pred))\nprint('KNears Neighbors: ', roc_auc_score(y_train, knears_pred))\nprint('Support Vector Classifier: ', roc_auc_score(y_train, svc_pred))\nprint('Decision Tree Classifier: ', roc_auc_score(y_train, tree_pred))","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:05:39.335993Z","iopub.execute_input":"2024-05-16T12:05:39.336299Z","iopub.status.idle":"2024-05-16T12:05:39.350653Z","shell.execute_reply.started":"2024-05-16T12:05:39.336274Z","shell.execute_reply":"2024-05-16T12:05:39.349750Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,log_reg.predict(x_test)))\nprint(classification_report(y_test,knears_neighbors.predict(x_test)))\nprint(classification_report(y_test,svc.predict(x_test)))","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:05:39.741040Z","iopub.execute_input":"2024-05-16T12:05:39.741417Z","iopub.status.idle":"2024-05-16T12:05:39.786360Z","shell.execute_reply.started":"2024-05-16T12:05:39.741391Z","shell.execute_reply":"2024-05-16T12:05:39.785453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install keras","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:05:41.113078Z","iopub.execute_input":"2024-05-16T12:05:41.113753Z","iopub.status.idle":"2024-05-16T12:05:54.025489Z","shell.execute_reply.started":"2024-05-16T12:05:41.113722Z","shell.execute_reply":"2024-05-16T12:05:54.024160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nfrom keras import backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Activation, Dense\nfrom keras.optimizers import Adam\nfrom keras.metrics import categorical_crossentropy\n\nn_inputs =x_train.shape[1]\n\nundersample_model = Sequential([\n    Dense(n_inputs, input_shape=(n_inputs, ), activation='relu'),\n    Dense(32, activation='relu'),\n    Dense(2, activation='softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:15:02.744439Z","iopub.execute_input":"2024-05-16T12:15:02.745108Z","iopub.status.idle":"2024-05-16T12:15:03.394118Z","shell.execute_reply.started":"2024-05-16T12:15:02.745079Z","shell.execute_reply":"2024-05-16T12:15:03.393157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"undersample_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"undersample_model.compile(Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:19:35.708336Z","iopub.execute_input":"2024-05-16T12:19:35.709249Z","iopub.status.idle":"2024-05-16T12:19:35.724172Z","shell.execute_reply.started":"2024-05-16T12:19:35.709218Z","shell.execute_reply":"2024-05-16T12:19:35.723171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"undersample_model.fit(x_train, y_train, validation_split=0.2, batch_size=25, epochs=20, shuffle=True, verbose=2)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:20:12.887467Z","iopub.execute_input":"2024-05-16T12:20:12.888188Z","iopub.status.idle":"2024-05-16T12:20:19.312997Z","shell.execute_reply.started":"2024-05-16T12:20:12.888157Z","shell.execute_reply":"2024-05-16T12:20:19.312057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"undersample_model.evaluate(x_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T12:47:37.245329Z","iopub.execute_input":"2024-05-16T12:47:37.246081Z","iopub.status.idle":"2024-05-16T12:47:37.324331Z","shell.execute_reply.started":"2024-05-16T12:47:37.246050Z","shell.execute_reply":"2024-05-16T12:47:37.323376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}